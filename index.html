<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Anna Apricitas Noyes — Grounding & Accountability for AI-Mediated Trust</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <div class="header-text">AI TRUST & SAFETY</div>
        <nav class="main-nav">
  <a href="index.html" class="active">Home</a>
  <a href="about.html">About</a>
  <a href="author-musician.html">Author & Musician</a>
  <a href="writing.html">Creative Writing</a>
  <a href="mailto:anna_mariasa@yahoo.com">Contact</a>
</nav>

    </header>

    <main>
        <div class="profile-image">
            <img src="headshot.jpg" alt="Headshot of Anna Apricitas Noyes">
        </div>

        <h1>Anna Apricitas Noyes</h1>
        
        <p class="tagline">
            Grounding & accountability frameworks for AI-mediated trust—focused on over-reliance,
            misattributed authority, and preserving human judgment in high-stakes, public-facing contexts.
        </p>

        <div class="tags">
            <span class="tag">AI Trust & Safety</span>
            <span class="tag">Grounding</span>
            <span class="tag">Accountability</span>
            <span class="tag">Over-Reliance Risk</span>
            <span class="tag">Human-in-the-Loop Evaluation</span>
            <span class="tag">Education / Public-Facing Use</span>
        </div>

        <section class="scope-section">
            <h2>Scope</h2>
            <p>
                This site is intentionally minimal. It shows the shape of the work without posting full texts publicly.
            </p>
            <p>
                The archive examines how fluent conversational systems can be mistaken for grounded authority or care—
                especially in high-stakes contexts. The aim is to reduce unsafe dependence and preserve explicit human accountability.
            </p>
            <p>
                Framework summaries and evaluation criteria are available to qualified teams upon request.
            </p>
            <p class="guiding-principle">
                <strong>Guiding principle:</strong> AI systems are tools, not moral agents.
            </p>
        </section>

        <section>
            <h2>What This Work Addresses</h2>
            <ul>
                <li>Authority transfer through conversational fluency</li>
                <li>Unsafe reliance formation in educational and health-adjacent contexts</li>
                <li>Responsibility displacement in human-AI interaction</li>
                <li>Evaluation criteria for interaction-level risk (beyond content compliance)</li>
            </ul>
        </section>

        <section>
            <h2>Selected Frameworks</h2>
            <p style="margin-bottom: 24px; font-size: 14px; color: var(--text-muted);">
                <em>Click framework titles to expand details</em>
            </p>
            
            <div class="framework-item">
                <h3 class="expandable" onclick="toggleFramework('framework1')">
                    Warped Mirror Protocol 
                    <span class="expand-icon" id="icon1">▼</span>
                </h3>
                <div class="expandable-content" id="framework1">
                    <p>
                        Identifying when reflective fluency creates false attribution of moral agency or grounded authority.
                        This framework addresses how conversational systems that mirror user values, concerns, or emotional 
                        states can be mistaken for systems that actually hold moral accountability or expertise.
                    </p>
                    <p>
                        <strong>Core risk:</strong> Users may treat reflection as endorsement, continuity as responsibility, 
                        or empathetic response as grounded care.
                    </p>
                    <p style="font-style: italic; margin-top: 16px;">
                        Detailed protocol available upon request.
                    </p>
                </div>
            </div>

            <div class="framework-item">
                <h3 class="expandable" onclick="toggleFramework('framework2')">
                    Essential Version of AI Accountability 
                    <span class="expand-icon" id="icon2">▼</span>
                </h3>
                <div class="expandable-content" id="framework2">
                    <p>
                        Ensuring accountability remains anchored externally to human decision-makers. 
                        This framework defines where responsibility must remain human even as AI systems become 
                        more sophisticated in their advisory or supportive roles.
                    </p>
                    <p>
                        <strong>Core principle:</strong> AI systems can inform, but cannot be accountable. 
                        Responsibility must remain with identifiable human actors who can be held to account.
                    </p>
                    <p style="font-style: italic; margin-top: 16px;">
                        Full framework and implementation guidance available upon request.
                    </p>
                </div>
            </div>

            <div class="framework-item">
                <h3 class="expandable" onclick="toggleFramework('framework3')">
                    What Remains 
                    <span class="expand-icon" id="icon3">▼</span>
                </h3>
                <div class="expandable-content" id="framework3">
                    <p>
                        Defining what must remain human in AI-mediated judgment and care contexts. 
                        As systems become more capable of sophisticated reasoning and empathetic response, 
                        this framework articulates the boundaries that must not be crossed.
                    </p>
                    <p>
                        <strong>Key question:</strong> What forms of judgment, care, and authority should remain 
                        fundamentally human even if AI systems could technically perform them?
                    </p>
                    <p style="font-style: italic; margin-top: 16px;">
                        Framework document available to safety and ethics teams upon request.
                    </p>
                </div>
            </div>

            <div class="framework-item">
                <h3 class="expandable" onclick="toggleFramework('framework4')">
                    Maps / Tapestry / The Other Side 
                    <span class="expand-icon" id="icon4">▼</span>
                </h3>
                <div class="expandable-content" id="framework4">
                    <p>
                        Boundary conditions and identifiable failure modes in conversational AI. 
                        This framework maps the territory where interaction-level risks become acute, 
                        providing evaluable criteria for detecting when systems are approaching problematic dynamics.
                    </p>
                    <p>
                        <strong>Focus areas:</strong> Gradual authority transfer, escalating reliance, 
                        responsibility diffusion, and the cumulative effects of repeated interaction patterns.
                    </p>
                    <p style="font-style: italic; margin-top: 16px;">
                        Evaluation criteria and case studies available upon request.
                    </p>
                </div>
            </div>
        </section>

        <section>
            <h2>Request Access</h2>
            <p>
                Materials are shared selectively upon request. Written, asynchronous engagement preferred.
            </p>
            <p class="contact-email">
                Contact: <a href="mailto:anna_mariasa@yahoo.com">anna_mariasa@yahoo.com</a>
            </p>
            <p class="contact-note">
                Additional reference materials are available upon request.
            </p>
        </section>
    </main>

    <footer>
        <p>© Anna Apricitas Noyes • Professional Archive</p>
    </footer>

    <script>
        // Interactive framework expansion
        function toggleFramework(id) {
            const content = document.getElementById(id);
            const icon = document.getElementById('icon' + id.charAt(id.length - 1));
            
            if (content.classList.contains('open')) {
                content.classList.remove('open');
                icon.classList.remove('rotated');
            } else {
                // Close all other frameworks
                document.querySelectorAll('.expandable-content').forEach(item => {
                    item.classList.remove('open');
                });
                document.querySelectorAll('.expand-icon').forEach(ic => {
                    ic.classList.remove('rotated');
                });
                
                // Open this one
                content.classList.add('open');
                icon.classList.add('rotated');
            }
        }
    </script>
</body>
</html>
